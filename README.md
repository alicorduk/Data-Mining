Sentiment Analysis and Deep Learning Project
![Company Logo](https://github.com/alicorduk/Data-Mining/blob/main/Final%20Synthesis%20Assignment/amazon-logo.jpg)


ğŸ“– Overview
This project involves analyzing a dataset of Amazon reviews to build predictive models for sentiment classification. Using a combination of machine learning and deep learning techniques, the aim is to evaluate and compare model performance for identifying positive and negative sentiments in review texts.

## ğŸš€ Key Features
Data preprocessing and analysis using Python.
Sentiment classification using various Machine Learning Models:
Naive Bayes
Logistic Regression
Support Vector Machines (SVM)
Random Forest
Advanced Deep Learning approach:
Long Short-Term Memory (LSTM) networks with embedding layers.
Model evaluation using metrics like ROC AUC, Precision-Recall AUC, and F1-Score.
## ğŸ›  Tools & Libraries
Programming Language: Python
Libraries Used:
Pandas, Numpy (Data Processing)
Scikit-learn (Machine Learning Models)
TensorFlow & Keras (Deep Learning)
Matplotlib & Seaborn (Visualization)
## ğŸ“‚ Dataset
Source: Amazon Reviews Dataset
Target Variable: overall (Ratings categorized as sentiment labels)
Features Explored:
reviewText
product_price
helpful_votes, etc.
ğŸ“ Workflow
Data Cleaning: Handle missing values and preprocess text data.
Exploratory Data Analysis (EDA): Understand data distribution and sentiment balance.
Feature Engineering: Tokenization and embedding for text data.
Model Training:
Implemented machine learning and deep learning models.
Fine-tuned LSTM with embedding, pooling, and dense layers.
Evaluation: Assessed model performance using metrics such as accuracy, precision, recall, and F1-score.
## ğŸ” Results
Machine Learning Models:
Best performing: Logistic Regression (ROC AUC: X.X)
Deep Learning Models:
LSTM outperformed machine learning models with (Precision-Recall AUC: X.X).
## ğŸ“ˆ Visualizations
Included visualizations for:

Data distribution.
Model performance comparison.
Training vs. Testing accuracy.
## ğŸ’» How to Run
Clone the repository:
bash
Copy code
git clone <repository_url>
Install dependencies:
bash
Copy code
pip install -r requirements.txt
Run the Jupyter Notebook:
bash
Copy code
jupyter notebook
Explore the outputs and visualizations in the notebook.
ğŸ¤ Acknowledgments
